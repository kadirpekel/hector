global:
  a2a_server:
    enabled: true
    host: "0.0.0.0"
    port: 8080
agents:
  local_researcher:
    type: "native"  
    name: "Local Research Agent"
    description: "Native agent that gathers information"
    llm: "main-llm"
    tools:
      - execute_command
    reasoning:
      engine: "chain-of-thought"
      max_iterations: 5
    prompt:
      system_role: |
        You are a research specialist. Gather comprehensive information
        and provide clear, well-structured summaries.
  local_writer:
    name: "Local Content Writer"
    description: "Native agent that creates written content"
    llm: "main-llm"
    tools:
      - write_file
    reasoning:
      engine: "chain-of-thought"
      max_iterations: 5
    prompt:
      system_role: |
        You are a professional content writer. Create clear,
        engaging content with proper structure.
  external_specialist:
    type: "a2a"  
    name: "External Specialist"
    description: "External A2A agent with specialized capabilities"
    url: "localhost:8080"  
  partner_analyst:
    type: "a2a"
    name: "Partner Analysis Agent"
    description: "Third-party A2A agent for data analysis"
    url: "localhost:8082"  
  orchestrator:
    type: "native"
    name: "Hybrid Orchestrator"
    description: "Orchestrates both local and external agents"
    llm: "main-llm"
    tools:
      - agent_call  
    reasoning:
      engine: "supervisor"
      max_iterations: 10  
    memory:
      working:
        strategy: "summary_buffer"
        budget: 16000      
        threshold: 0.85    
        target: 0.70       
    prompt:
      system_role: |
        You orchestrate a team of specialized agents.
        AVAILABLE AGENTS:
        - local_researcher: Local research specialist (native)
        - local_writer: Local content creator (native)
        - external_specialist: Remote specialist (external A2A)
        - partner_analyst: Partner's analyst (external A2A)
        Delegate tasks to the most appropriate agent, whether local or remote.
        The A2A protocol makes them all equally accessible!
llms:
  main-llm:
    type: "openai"
    model: "gpt-4o-mini"
    api_key: "${OPENAI_API_KEY}"
    temperature: 0.7
    max_tokens: 4000
tools:
  execute_command:
    type: command
    enable_sandboxing: true  
    working_directory: "."
  write_file:
    type: write_file
    working_directory: "./output"
